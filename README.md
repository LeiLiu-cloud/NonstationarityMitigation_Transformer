# Spatial Nonstationarity Mitigation with Vision Transformer
## Description
* This work applied vision transformers to mitigate the spatial nonstationarity impacts on deep learning model prediction performance.
* The benchmark results are from the convolutional neural network (CNN) model. The ViT and SwinT models are based on original ViT and SwinT model with minor modification for the regression task.

## Content
- deep learning models: CNN.py, ViT.py, SwinT.py
- data: traning & testing data preparation
- train.py
## Acknowledgements
This work is supported by Digital Reservoir Characterization Technology (DIRECT) Industry Affiliate Program at the University of Texas at Austin.
## Contacts
- if you have any questions, please contact Lei Liu (leiliu@utexaas.edu)
- for more machine learning & data analytics demos, please check GeostatsGuy (https://github.com/GeostatsGuy).
