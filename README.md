# Spatial Nonstationarity Mitigation with Vision Transformer
## Description
* This work applied vision transformers to mitigate the spatial nonstationarity impacts on deep learning model prediction performance.
* The benchmark results are from the convolutional neural network (CNN) model. The ViT and SwinT models are based on original ViT and SwinT model with some modifications for the regression task.

## Implementation & Content
__Software__: `Python`
__Packages__: `PyTorch`, `Tensorflow`, `GSLIB`, `numpy`, `sklearn`, `matplotlib`

The detaield content include:
- deep learning models: CNN.py, ViT.py, SwinT.py
- data preparation: traning & testing data preparation
- training: train.py
## Acknowledgements
This work is supported by Digital Reservoir Characterization Technology (DIRECT) Industry Affiliate Program at the University of Texas at Austin.
## Contacts
- if you have any questions, please contact Lei Liu (leiliu@utexaas.edu)
- for more machine learning & data analytics demos, please check GeostatsGuy (https://github.com/GeostatsGuy).
